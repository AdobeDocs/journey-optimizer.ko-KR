---
solution: Journey Optimizer
product: journey optimizer
title: 콘텐츠 실험 시작
description: Journey Optimizer 콘텐츠 실험에 대해 자세히 알아보기
feature: Experimentation
topic: Content Management
role: User
level: Beginner
keywords: 시작하기, 시작, 콘텐츠, 실험
exl-id: 7fe4b24e-f60a-4107-a064-00010b0cbbfc
source-git-commit: 1490ac2efd39c6bf9b6ca97e682750463e9f054d
workflow-type: tm+mt
source-wordcount: '1980'
ht-degree: 100%

---

# 콘텐츠 실험 시작하기 {#get-started-experiment}

## 콘텐츠 실험이란 무엇인가요?

콘텐츠 실험을 통해 캠페인 작업에 사용할 콘텐츠를 최적화할 수 있습니다.

실험은 무작위화한 시험 회기 여러 개를 모아 놓은 것입니다. 온라인 테스팅 맥락에서는 무작위로 선택한 사용자 일부를 특정한 버전의 메시지에 노출하고, 무작위로 선택한 다른 사용자들을 또 다른 처리에 노출하는 것을 말합니다. 메시지를 보낸 후에는 궁금한 결과 지표(예: 이메일 오픈 수 또는 클릭 수)를 측정할 수 있습니다.

## 실험을 하는 이유는 무엇입니까?

![](assets/content_experiment_schema.png)

실험을 통해 지표 개선으로 이어지는 변경 내용을 분리하여 확인할 수 있습니다. 위의 이미지에 표시된 것처럼, 무작위로 선택한 일부 사용자를 각 처리 그룹에 노출하므로 참가 그룹은 평균적으로 유사한 특성을 공유하게 됩니다. 따라서 그룹 간에 차이가 난다면 이는 받은 처리에 따른 차이로 해석할 수 있습니다. 즉, 실험자가 변경한 내용과 확인하고자 하는 결과 사이에 인과 관계를 수립할 수 있습니다.

이를 통해 비즈니스 목표를 최적화하는 과정에서 데이터에 기반한 결정을 내릴 수 있습니다.

Adobe Journey Optimizer 콘텐츠 실험으로 테스트해 볼 수 있는 아이디어의 예시는 다음과 같습니다.

* **제목**: 제목의 톤이나 개인화 정도를 변경하면 어떤 효과가 있을까?
* **메시지 콘텐츠**: 이메일의 시각적 레이아웃을 변경하면 이메일 클릭 수가 늘어날까?

## 콘텐츠 실험의 원리는 무엇입니까? {#content-experiment-work}

### 무작위 할당

Adobe Journey Optimizer의 콘텐츠 실험에서는 방문자 신원의 의사 무작위 해시를 사용하여 타겟 대상자 범위에 있는 사용자를 실험자가 정의한 처리 중 하나에 무작위로 할당합니다. 해시 메커니즘을 통해 방문자가 한 캠페인에 여러 번 들어오는 경우에도 결과적으로 동일한 처리를 받도록 할 수 있습니다.

구체적으로 살펴보자면 MumurHash3 32비트 알고리즘을 사용하여 사용자 신원 문자열을 10,000개의 버킷 중 하나로 해시합니다. 콘텐츠 실험에서 각 처리에 트래픽을 50%씩 할당하는 경우 1~5,000번 버킷에 해당하는 사용자는 첫 번째 처리, 5,001~10,000번 버킷에 해당하는 사용자는 두 번째 처리에 노출됩니다. 유사 무작위 해시를 사용하므로 방문자의 분할이 50:50이 아닌 것으로 관찰될 수도 있지만, 타겟 분할 백분율과 통계적으로는 같습니다.

콘텐츠 실험으로 모든 캠페인을 구성할 때는 신원 네임스페이스를 선택해야 합니다. 무작위화 알고리즘에서는 이 네임스페이스의 사용자 ID를 선택합니다. 이는 [실행 주소](../configuration/primary-email-addresses.md)와는 독립적입니다.

### 데이터 수집 및 분석

할당 시점, 즉 아웃바운드 채널을 통해 사용자에게 메시지를 보내거나 사용자가 인바운드 채널에서 캠페인에 들어오는 시점에 “할당 레코드”가 해당되는 시스템 데이터 세트에 기록됩니다. 이 레코드에는 사용자가 할당된 처리 그룹과 함께 실험과 캠페인의 식별자가 기록됩니다.

목표 지표는 두 가지 기본 클래스로 나눌 수 있습니다.

* 직접 지표는 사용자가 처리에 직접 반응하는 경우를 말합니다(예: 이메일 열기, 링크 클릭).
* 간접 또는 “깔때기 아래쪽” 지표는 사용자가 처리에 노출된 이후에 나타납니다.

Adobe Journey Optimizer가 메시지를 추적하는 직접적 목표 지표의 경우에는 최종 사용자의 반응 이벤트에 캠페인과 처리 식별자가 자동으로 태그되므로 반응 지표를 처리와 직접 연결할 수 있습니다. [추적에 대해 자세히 알아보십시오](../email/message-tracking.md).

![](assets/technote_2.png)

구매 등 간접 또는 “깔때기 아래쪽” 목표의 경우, 최종 사용자의 반응 이벤트에 캠페인과 처리 식별자가 태깅되지 않습니다. 즉, 처리 노출 후 구매 이벤트가 발생하며 이전 처리 할당과 해당 구매 사이에 직접적인 연관성은 없습니다. 이런 지표를 분석할 때 Adobe는 다음 경우에만 처리와 깔때기 하단 구매 전환 이벤트를 연결합니다.

* 할당과 구매 전환 이벤트 시점에 사용자 신원이 동일한 경우.
* 구매 전환이 처리 할당 후 7일 내에 이루어진 경우.

![](assets/technote_3.png)

이렇게 연결한 다음에는 Adobe Journey Optimizer가 &quot;언제든 유효한&quot; 고급 통계 방법론으로 이 원시 보고 데이터를 해석하여 사용자가 실험 보고서를 해석할 수 있도록 해 줍니다. 자세한 정보는 이 [페이지](../campaigns/experiment-calculations.md)를 참조하십시오.

## 실험 진행 팁

실험을 진행할 때는 특정 모범 사례를 따르는 것이 중요합니다. 다음은 실험을 진행하기 위한 몇 가지 팁입니다.

+++테스트할 변수 분리하기

테스트할 가설을 만든 후 이 가설에 따른 변경을 가능한 한 적은 수준으로 제한하여 게재에 어떤 영향이 있는지 파악합니다.

예를 들어 이메일 제목의 개인화가 오픈율 상승을 유도하는지 여부는 좋은 가설입니다. 하지만 메시지 콘텐츠나 이미지에 변경을 추가하면 결론에 혼동이 있을 수 있습니다.
+++

+++적절한 지표 사용하기

타겟팅할 지표를 정하고 변경할 내용이 이 지표에 직접적인 영향을 줄 수 있는지 확인합니다.

예를 들어 메시지 본문의 콘텐츠를 변경하는 것은 이메일 오픈율에 영향을 주지 않습니다.
+++

+++테스트를 적절한 수의 대상자에 대해 진행하거나 충분히 오랫동안 진행하기

테스트를 더 오래 진행하면 처리에 따라 목표 지표에 나타나는 더 작은 차이도 감지할 수 있습니다. 하지만 목표 지표의 기준선 값이 작은 경우에는 샘플 크기가 더 커야 합니다.
실험에 포함해야 하는 사용자 수는 찾으려는 효과의 크기, 목표 지표의 분산이나 확산도, 긍정 오류와 부정 오류 허용치 등에 따라 달라집니다. 고전적인 실험인 경우 [샘플 크기 계산기](https://experienceleague.adobe.com/tools/calculator/testcalculator.html?lang=ko-KR){_blank}로 테스트를 진행해야 하는 기간을 결정할 수 있습니다.
+++

+++통계적 불확실성 이해하기

1,000명의 사용자가 한 번의 처리에 노출되는 실험을 진행했고 전환율이 5%로 나타난 경우를 생각해 보겠습니다. 이 값은 사용자 전체가 같은 처치에 노출되었을 때 실제 전환율과 같을까요? 실제 전환율은 몇 %일까요?
통계적 방법으로 그 불확실성을 공식화할 수 있습니다. 온라인 실험을 진행할 때 이해해야 할 가장 중요한 개념 중 하나는 관찰된 전환율이 근본적인 실제 전환율 범위와 어느 정도 일치해야 한다는 것입니다. 즉, 측정치가 충분히 정밀해진 이후에 결과를 도출해야 합니다. 신뢰 구간과 신뢰도는 이 불확실성을 정량화하는 데 도움이 됩니다.
+++

+++새 가설을 세우고 지속적으로 테스트하기

진정한 비즈니스 인사이트를 얻으려면 실험 하나에만 집중해야 합니다. 대신 후속 실험을 합니다. 새로운 가설을 만들고, 다른 변수를 바꾸어 새 테스트를 진행하고, 다른 대상자를 대상으로 테스트하고, 다른 지표에 대한 영향을 확인할 수 있습니다.
+++

## 실험 결과 해석하기 {#interpret-results}

>[!CONTEXTUALHELP]
>id="ajo_campaigns_content_experiment_summary"
>title="요약 위젯"
>abstract="요약 위젯은 실험 결과가 결정적인지 여부를 포함하여 실험 결과에 대한 개요를 제공합니다. 빠르고 손쉽게 실험 결과를 이해할 수 있는 방법을 제공합니다."

![](assets/experimentation_report_3.png)

이 섹션에서는 실험 보고서에 대해 설명하고 결과로 나타나는 다양한 통계 수치를 이해하는 방법을 알아봅니다.

다음은 콘텐츠 실험 결과를 해석하기 위한 지침입니다.

결과 전체에 대한 설명은 단순히 효과가 결정적인지 여부를 선언하는 것이 아니라 가능한 증거(샘플 크기, 전환율, 신뢰 구간 등)를 모두 고려해야 한다는 점에 유의해야 합니다. 결과가 아직 확정적이지 않은 경우라도 서로 다른 처리 버전이 서로 다르다는 설득력 있는 증거가 나타날 수 있습니다.

통계적 계산에 대해 이해하려면 이 [페이지](../campaigns/experiment-calculations.md)를 참조하십시오.

### 1. 표준화한 지표 비교하기 {#normalized-metrics}

두 처리 버전의 성과를 비교할 때에는 항상 표준화한 지표를 비교해야 각 처리 버전에 노출된 프로필 수의 차이를 고려할 수 있습니다.

예를 들어 실험에서 **[!UICONTROL 고유 오픈 수]**&#x200B;를 측정 목표로 해당 처리 버전에 프로필 10,000개를 노출했을 때 고유 오픈 수가 200으로 기록되었다면 이 결과는 **[!UICONTROL 전환율]** 2%로 나타납니다. 고유하지 않은 지표(예: 오픈 수 지표)의 경우 표준화된 지표는 **[!UICONTROL 프로필당 카운트]**&#x200B;로 나타나고, 가격 총계 등 연속 지표의 경우 표준화된 지표는 **[!UICONTROL 프로필당 총합]**&#x200B;으로 나타납니다.

### 2. 신뢰 구간에 집중하기 {#confidence-intervals}

프로필 샘플에 대해 실험을 진행하는 경우 특정 처리 버전에서 관찰된 전환율은 그 기저에 있는 실제 전환율의 추정치입니다.

예를 들어 처리 A의 **[!UICONTROL 전환율]**&#x200B;이 3%이고 처리 버전 B의 **[!UICONTROL 전환율]**&#x200B;이 2%로 관찰되었다면 처리 버전 A의 성과가 처리 B보다 좋은 것일까요? 이 질문에 답하려면 먼저 관찰된 전환율의 불확실성을 정량화해야 합니다.

신뢰 구간은 추정한 전환율의 불확실성을 정량화하는 데 도움이 됩니다. 신뢰 구간이 넓을수록 더 불확실하다는 뜻입니다. 실험에 더 많은 프로필이 추가될수록 구간이 좁아지며, 이는 추정치가 더 정확하다는 뜻입니다. 신뢰 구간은 관찰된 데이터와 호환이 가능한 전환율의 범위를 나타냅니다.

두 처리의 신뢰 구간이 거의 겹치지 않는다면 두 개의 전환율이 다르다는 뜻입니다. 하지만 두 처리의 신뢰 구간이 많이 겹친다면 두 개의 전환율이 같을 가능성이 더 높습니다.

Adobe은 95%의 언제나 유효한(Anytime Valid) 신뢰 구간(신뢰 시퀀스)를 사용합니다. 즉, 실험 중 언제든지 결과를 안전하게 볼 수 있습니다.

### 3. 상승도 이해하기 {#understand-lift}

실험 보고서 요약에는 **[!UICONTROL 기준선 대비 상승도]**&#x200B;가 표시됩니다. 이 지표는 특정 처리의 전환율이 기준선 대비 향상된 정도를 백분율로 측정한 것입니다. 정확하게 정의하면 해당 처리 버전과 기준선 간 성과의 차이를 기준선의 성과로 나눈 값을 백분율로 표현한 것입니다.

### 3. 신뢰도 이해하기 {#understand-confidence}

각 처리의 성과를 확인할 때는 일단 **[!UICONTROL 신뢰 구간]**&#x200B;에 집중해야 하지만, Adobe는 신뢰도도 표시합니다. 신뢰도는 특정 처리와 기준선 처리가 동일하다는 증거가 얼마나 많은지 확률론적으로 측정한 것입니다. 신뢰도가 높을수록 기준선과 기준선이 아닌 처리의 성과가 동일하다는 가정의 증거가 적다는 것을 나타냅니다. 더 정확히 말하자면 보고서에 표시되는 신뢰도는 특정 처리와 기준선 간 전환율 차이가 관찰되었을 때, 사실은 실제 기저에 있는 전환율 간에 차이가 없는 경우 현재 결과보다 더 적은 차이가 관찰되었을 확률(백분율로 표현)입니다. p값으로 나타내자면 표시되는 신뢰도는 1 - p값입니다.

Adobe는 위에서 설명한 신뢰 시퀀스와 마찬가지로 “언제나 유효한” 신뢰 구간과 &quot;언제나 유효한&quot; p값을 사용합니다.

### 4. 통계적 유의성

실험을 진행할 때 특정 처리와 기준선의 실제 기저에 있는 전환율/성과가 동일하다는 null 가설이 맞다면 특정 결과가 관찰되었을 확률이 매우 낮은 경우, 그 결과는 통계적으로 유의한 것으로 간주됩니다.

Adobe은 신뢰도가 95%를 넘는 경우 실험의 결과가 결정적이라고 선언합니다.

## 실험 후 할 일

실험을 진행한 후에는 몇 가지 후속 작업을 할 수 있습니다.

* **좋은 결과를 얻은 아이디어 활용하기**

  분명한 결과가 나타난 경우 성공적인 아이디어를 활용할 수 있습니다. 가장 성과가 좋은 처리를 고객 전체에게 적용하거나, 그 처리의 구조가 재현되는 새로운 캠페인을 만들 수도 있습니다.
  </br>동적 환경에서는 한 번 결과가 좋았던 처치여도 나중에는 같은 결과가 나오지 않을 수 있다는 점에 유의하십시오.

* **후속 테스트 진행하기**

  실험 결과가 결정적이지 않을 수도 있습니다. 처리 간 차이를 찾아내기에 충분한 프로필을 포함하지 않았거나, 정의한 처리가 충분히 다르지 않기 때문에 이런 결과가 발생하기도 합니다.

  결정적이지 않은 결과가 나왔지만 테스트한 가설은 아직 적절한 경우, 적합한 후속 조치는 수가 더 많은 대상자나 다른 대상자에 대해 후속 테스트를 진행하거나, 보다 명확한 차이가 나타날 수 있도록 처리를 수정하는 것 등이 될 수 있습니다.

* **보다 심층적으로 분석하기**

  한 대상자에 효과가 있는 처리가 다른 대상자에게는 적합하지 않을 수도 있습니다. 다양한 대상자를 처리한 후 효과가 어떻게 나타나는지 심층적으로 분석하면 새로운 테스트에 대한 아이디어를 도출하는 데 도움이 됩니다.

  마찬가지로 다양한 지표에서 각 처리의 성과를 확인하면 실험 결과를 보다 종합적인 관점에서 확인할 수 있습니다.

  >[!CAUTION]
  >
  >추가 분석을 하면 가짜 효과(긍정 오류)를 찾아낼 가능성도 높아집니다.
